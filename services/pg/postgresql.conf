################################################################################
# settings from the original image
################################################################################

listen_addresses = '*'
dynamic_shared_memory_type = posix
log_timezone = 'Etc/UTC'
datestyle = 'iso, mdy'
timezone = 'Etc/UTC'
lc_messages = 'en_US.utf8'                      # locale for system error message
lc_monetary = 'en_US.utf8'                      # locale for monetary formatting
lc_numeric = 'en_US.utf8'                       # locale for number formatting
lc_time = 'en_US.utf8'                          # locale for time formatting
default_text_search_config = 'pg_catalog.english'

synchronous_commit = 'off'

# FIXME:
# these are aggressive autovacuum settings;
# they're added because some of the rollup tables can do lots of updates that need vacuuming;
# these should be added automatically per-table by the pgrollup library,
# and the settings values should be tuned
# see: https://dba.stackexchange.com/questions/21068/aggressive-autovacuum-on-postgresql/21649
log_autovacuum_min_duration = 0
autovacuum_max_workers = 40
autovacuum_naptime = 15s
autovacuum_vacuum_threshold = 25
autovacuum_vacuum_scale_factor = 0.1
autovacuum_analyze_threshold = 10
autovacuum_analyze_scale_factor = 0.05
autovacuum_vacuum_cost_delay = 10ms
autovacuum_vacuum_cost_limit = 1000

################################################################################
# extensions
################################################################################

shared_preload_libraries = 'citus, pg_stat_statements, pg_cron, pg_partman_bgw'
cron.database_name = 'novichenko'
citus.max_intermediate_result_size = -1
citus.shard_count = 64
citus.replication_model = 'streaming'

################################################################################
# settings from pgtune
################################################################################

# WARNING
# this tool not being optimal
# for very high memory systems

# DB Version: 12
# OS Type: linux
# DB Type: dw
# Total Memory (RAM): 128 GB
# CPUs num: 40
# Data Storage: hdd

max_connections = 100
shared_buffers = 8GB
effective_cache_size = 96GB
maintenance_work_mem = 2GB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 500
#random_page_cost = 4
random_page_cost = 1.1
effective_io_concurrency = 2
work_mem = 64MB
min_wal_size = 4GB
max_wal_size = 16GB
max_worker_processes = 40
max_parallel_workers_per_gather = 20
max_parallel_workers = 40
max_parallel_maintenance_workers = 8
